{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIc15opVTZ7y"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trials_df = pd.read_csv(\"/content/mavrik_trials_parsed_latest.csv\")"
      ],
      "metadata": {
        "id": "HeWxpTtuTcqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trials_df"
      ],
      "metadata": {
        "id": "_NzOlkmGTctB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trials_df = trials_df.drop_duplicates(subset=['NCT_ID'], keep='first').reset_index(drop=True)"
      ],
      "metadata": {
        "id": "n8i2NqNMTcvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trials_df"
      ],
      "metadata": {
        "id": "KH18I3hcTcyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.reset_option('display.max_colwidth')\n",
        "pd.reset_option('display.max_rows')"
      ],
      "metadata": {
        "id": "uRlbepVLTj0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option(\"display.max_rows\", None)"
      ],
      "metadata": {
        "id": "9n6caocxTk3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_colwidth', None)"
      ],
      "metadata": {
        "id": "Ova81lgbTk6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trials_df[[\"NCT_ID\",\"Brief_Summary\",\"Eligibility\",\"eligibility_json\"]].loc[59]"
      ],
      "metadata": {
        "id": "tQ3ooAmnTk8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "elgibiltiy_df = pd.read_csv(\"/content/patiens_trials_elgibiltiy.csv\")"
      ],
      "metadata": {
        "id": "Q6EvO-iDTk-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "elgibiltiy_df.loc[elgibiltiy_df[\"trial_id\"] == \"NCT03346728\", \"trial_id\"] = \"NCT03361228\""
      ],
      "metadata": {
        "id": "huiel50JTlBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "elgibiltiy_df = elgibiltiy_df.rename(columns={\"trial_id\": \"NCT_ID\"})"
      ],
      "metadata": {
        "id": "uluIeAKsTlDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "elgibiltiy_df[\"unique_patient_id\"] = elgibiltiy_df[\"NCT_ID\"] + \"_\" + elgibiltiy_df[\"patient_id\"]"
      ],
      "metadata": {
        "id": "2o2M-mgHTu5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "elgibiltiy_df = elgibiltiy_df.merge(\n",
        "    trials_df[[\"NCT_ID\", \"eligibility_json\"]],\n",
        "    on=\"NCT_ID\",\n",
        "    how=\"left\"\n",
        ")"
      ],
      "metadata": {
        "id": "yPHuMGobTu8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "elgibiltiy_df"
      ],
      "metadata": {
        "id": "dy7SeR2ETu_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "elgibiltiy_df.to_csv(\"/content/patiens_trials_elgibiltiy_final.csv\", index=False)"
      ],
      "metadata": {
        "id": "luIenHM6TvBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "elgibiltiy_df = pd.read_csv(\"/content/patiens_trials_elgibiltiy_final.csv\")"
      ],
      "metadata": {
        "id": "9Ak5yCTITvDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "elgibiltiy_df.sample(5)"
      ],
      "metadata": {
        "id": "j0J-9zowUGQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counts_df = elgibiltiy_df.groupby(\"NCT_ID\").size().reset_index(name=\"record_count\")\n",
        "print(counts_df)"
      ],
      "metadata": {
        "id": "llRG22NxTlFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "elgibiltiy_df['is_eligible'].value_counts()"
      ],
      "metadata": {
        "id": "usvaVh91UH8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import ast\n",
        "df =elgibiltiy_df.copy()\n",
        "def fix_json_column(col):\n",
        "    def convert(x):\n",
        "        # If already a dict → dump to JSON\n",
        "        if isinstance(x, dict):\n",
        "            return json.dumps(x)\n",
        "\n",
        "        # Try JSON first\n",
        "        try:\n",
        "            return json.dumps(json.loads(x))\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        # Try Python dict format\n",
        "        try:\n",
        "            py_obj = ast.literal_eval(x)\n",
        "            return json.dumps(py_obj)\n",
        "        except Exception as e:\n",
        "            print(\"BAD JSON:\", x)\n",
        "            raise e\n",
        "\n",
        "    return col.apply(convert)\n",
        "\n",
        "\n",
        "df[\"patient_json\"] = fix_json_column(df[\"patient_json\"])\n",
        "df[\"eligibility_json\"] = fix_json_column(df[\"eligibility_json\"])\n"
      ],
      "metadata": {
        "id": "dXCXjAgsUKq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_example(row):\n",
        "    instruction = (\n",
        "        \"Decide whether the following patient is eligible for the given clinical trial, \"\n",
        "        \"and provide reasoning for your decision.\"\n",
        "    )\n",
        "\n",
        "    input_data = {\n",
        "        \"patient\": json.loads(row[\"patient_json\"]),\n",
        "        \"trial_eligibility\": json.loads(row[\"eligibility_json\"]),\n",
        "    }\n",
        "\n",
        "    output = {\n",
        "        \"is_eligible\": bool(row[\"is_eligible\"]),\n",
        "        \"reasoning\": row[\"reasoning\"]\n",
        "    }\n",
        "\n",
        "    return {\n",
        "        \"instruction\": instruction,\n",
        "        \"input\": input_data,\n",
        "        \"output\": output,\n",
        "    }\n",
        "\n",
        "examples = df.apply(make_example, axis=1).tolist()\n"
      ],
      "metadata": {
        "id": "d-Dtg_3GUODg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip install --no-deps xformers trl peft accelerate bitsandbytes"
      ],
      "metadata": {
        "id": "BPMV6wHSUQRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Install latest Unsloth (supports DeepSpeed ZeRO-3 on Colab)\n",
        "\n",
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "\n",
        "# This is the magic line that makes 8B fit on T4\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=\"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n",
        "    max_seq_length=4096,\n",
        "    dtype=None,\n",
        "    load_in_4bit=True,\n",
        "    # This enables DeepSpeed ZeRO-3 automatically on Colab\n",
        "    use_gradient_checkpointing=\"unsloth\",\n",
        ")\n",
        "\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r=32,              # ↓ lowered from 64 to save VRAM\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                    \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0,\n",
        "    bias=\"none\",\n",
        "    use_gradient_checkpointing=\"unsloth\",\n",
        "    random_state=3407,\n",
        ")"
      ],
      "metadata": {
        "id": "DlLESVrAUSzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "import json\n",
        "\n",
        "# No split — use all data for training\n",
        "train_examples = examples\n",
        "\n",
        "# =====================================================\n",
        "# Formatting function\n",
        "# =====================================================\n",
        "\n",
        "def formatting_prompts_func(example):\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are an expert in assessing eligibility for oncology clinical trials. Decide whether the patient is eligible and explain your reasoning step by step.\"},\n",
        "        {\"role\": \"user\", \"content\": example[\"instruction\"] + \"\\n\\nPatient data and trial criteria:\\n\" + json.dumps(example[\"input\"], indent=2)},\n",
        "        {\"role\": \"assistant\", \"content\": json.dumps(example[\"output\"], indent=2)}\n",
        "    ]\n",
        "\n",
        "    text = \"\".join(\n",
        "        f\"<|begin_of_text|><|start_header_id|>{msg['role']}<|end_header_id|>\\n\\n{msg['content']}<|eot_id|>\"\n",
        "        for msg in messages\n",
        "    ) + \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\"\n",
        "\n",
        "    return {\"text\": text}\n",
        "\n",
        "# Build dataset\n",
        "train_dataset = Dataset.from_list([formatting_prompts_func(ex) for ex in train_examples])\n",
        "\n",
        "print(f\"Train size: {len(train_dataset)}\")\n",
        "\n",
        "\n",
        "# =====================================================\n",
        "# Training\n",
        "# =====================================================\n",
        "\n",
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=train_dataset,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=4096,\n",
        "    packing=True,\n",
        "    args=TrainingArguments(\n",
        "        per_device_train_batch_size=2,\n",
        "        gradient_accumulation_steps=4,\n",
        "        warmup_steps=5,\n",
        "        max_steps=40,\n",
        "        learning_rate=2e-4,\n",
        "        fp16=True,\n",
        "        bf16=False,\n",
        "        logging_steps=10,\n",
        "        save_strategy=\"steps\",\n",
        "        save_steps=40,\n",
        "        output_dir=\"/content/llama3.1-8b-clinical-eligibility\",\n",
        "        optim=\"adamw_8bit\",\n",
        "        seed=3407,\n",
        "        report_to=\"none\",\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "EkkvUP5yUZUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "QhowiejZUbh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final LoRA adapter saveing\n",
        "model.save_pretrained(\"/content/drive/MyDrive/Clinical_Trial_LLM/final_lora_adapter_3\")\n",
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/Clinical_Trial_LLM/final_lora_adapter_3\")"
      ],
      "metadata": {
        "id": "A2vWWNu1UeX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FVPYFhY_UnNO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}